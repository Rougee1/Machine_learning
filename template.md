# Template MLOps - Architecture ComplÃ¨te

Ce document dÃ©crit l'architecture complÃ¨te d'un pipeline MLOps et explique comment crÃ©er un nouveau projet en suivant cette structure.

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble de l'architecture](#vue-densemble-de-larchitecture)
2. [Technologies utilisÃ©es](#technologies-utilisÃ©es)
3. [Structure du projet](#structure-du-projet)
4. [Guide de crÃ©ation d'un nouveau projet](#guide-de-crÃ©ation-dun-nouveau-projet)
5. [Configuration dÃ©taillÃ©e de chaque composant](#configuration-dÃ©taillÃ©e-de-chaque-composant)

---

## Vue d'ensemble de l'architecture

Cette architecture MLOps complÃ¨te comprend :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pipeline MLOps Complet                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Ingestion  â”‚â”€â”€â”€â–¶â”‚   Training   â”‚â”€â”€â”€â–¶â”‚   Serving    â”‚     â”‚
â”‚  â”‚  (Prefect)   â”‚    â”‚  (Prefect +  â”‚    â”‚  (FastAPI)   â”‚     â”‚
â”‚  â”‚              â”‚    â”‚   MLflow)    â”‚    â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                    â”‚              â”‚
â”‚         â–¼                   â–¼                    â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  PostgreSQL â”‚    â”‚   Feature    â”‚    â”‚  Monitoring   â”‚     â”‚
â”‚  â”‚  (Database) â”‚    â”‚   Store      â”‚    â”‚ (Prometheus + â”‚     â”‚
â”‚  â”‚             â”‚    â”‚   (Feast)    â”‚    â”‚   Grafana)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                  â”‚   Drift      â”‚                              â”‚
â”‚                  â”‚  Detection   â”‚                              â”‚
â”‚                  â”‚  (Evidently) â”‚                              â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es

1. **Ingestion** : Les donnÃ©es brutes sont ingÃ©rÃ©es via Prefect, validÃ©es avec Great Expectations, et stockÃ©es dans PostgreSQL avec des snapshots temporels
2. **Feature Engineering** : Feast gÃ¨re les features de maniÃ¨re centralisÃ©e (offline pour training, online pour serving)
3. **Training** : Les modÃ¨les sont entraÃ®nÃ©s via Prefect, trackÃ©s avec MLflow, et stockÃ©s dans MLflow
4. **Serving** : FastAPI expose un endpoint de prÃ©diction qui utilise Feast pour rÃ©cupÃ©rer les features en temps rÃ©el
5. **Monitoring** : Prometheus collecte les mÃ©triques de l'API, Grafana les visualise, et Evidently dÃ©tecte le drift de donnÃ©es

---

## Technologies utilisÃ©es

### ğŸ—„ï¸ Base de donnÃ©es
- **PostgreSQL 16** : Base de donnÃ©es relationnelle pour stocker les donnÃ©es brutes, les snapshots temporels, et les mÃ©tadonnÃ©es
- **RÃ´le** : Source de vÃ©ritÃ© pour toutes les donnÃ©es du pipeline

### ğŸ”„ Orchestration
- **Prefect 3.6.1** : Orchestrateur de workflows pour gÃ©rer les pipelines d'ingestion, de training et de monitoring
- **RÃ´le** : Automatisation et orchestration des tÃ¢ches MLOps

### ğŸ“Š Feature Store
- **Feast 0.56.0** : Feature store open-source pour gÃ©rer les features de maniÃ¨re centralisÃ©e
- **RÃ´le** : 
  - Mode offline : rÃ©cupÃ©ration de features historiques pour l'entraÃ®nement
  - Mode online : rÃ©cupÃ©ration de features en temps rÃ©el pour les prÃ©dictions

### ğŸ¤– Machine Learning
- **MLflow 2.16.0** : Plateforme de gestion du cycle de vie des modÃ¨les ML
- **RÃ´le** : 
  - Tracking des expÃ©riences (paramÃ¨tres, mÃ©triques, artifacts)
  - Registry de modÃ¨les
  - DÃ©ploiement de modÃ¨les
- **Scikit-learn 1.7.2** : BibliothÃ¨que ML pour l'entraÃ®nement des modÃ¨les

### ğŸŒ API de prÃ©diction
- **FastAPI** : Framework web moderne pour crÃ©er l'API REST de prÃ©diction
- **Uvicorn** : Serveur ASGI pour exÃ©cuter FastAPI
- **RÃ´le** : Exposition d'un endpoint HTTP pour servir les prÃ©dictions en production

### ğŸ“ˆ Monitoring et ObservabilitÃ©
- **Prometheus 2.55.1** : SystÃ¨me de monitoring et collecte de mÃ©triques
- **Grafana 11.2.0** : Plateforme de visualisation et dashboards
- **Prometheus Client (Python)** : BibliothÃ¨que pour instrumenter l'API avec des mÃ©triques
- **RÃ´le** : Monitoring des performances de l'API (RPS, latence, erreurs)

### ğŸ” DÃ©tection de drift
- **Evidently 0.7.15** : BibliothÃ¨que pour dÃ©tecter le drift de donnÃ©es et la dÃ©gradation des modÃ¨les
- **RÃ´le** : Comparaison de distributions de donnÃ©es entre pÃ©riodes pour dÃ©tecter le drift

### âœ… Validation de donnÃ©es
- **Great Expectations 0.17.21** : Framework de validation de donnÃ©es
- **RÃ´le** : Validation de la qualitÃ© des donnÃ©es lors de l'ingestion

### ğŸ³ Containerisation
- **Docker** : Containerisation de tous les services
- **Docker Compose** : Orchestration multi-conteneurs
- **RÃ´le** : Isolation, reproductibilitÃ© et dÃ©ploiement facile

### ğŸ“¦ Gestion des dÃ©pendances
- **Python 3.11** : Langage de programmation principal
- **pip** : Gestionnaire de paquets Python
- **requirements.txt** : Fichiers de dÃ©pendances pour chaque service

---

## Structure du projet

```
mon-projet-mlops/
â”œâ”€â”€ api/                          # Service API FastAPI
â”‚   â”œâ”€â”€ app.py                    # Application FastAPI principale
â”‚   â”œâ”€â”€ Dockerfile                # Image Docker pour l'API
â”‚   â””â”€â”€ requirements.txt          # DÃ©pendances Python de l'API
â”‚
â”œâ”€â”€ services/                     # Services MLOps
â”‚   â”œâ”€â”€ prefect/                  # Service Prefect (orchestration)
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ ingest_flow.py        # Flow d'ingestion de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ train_baseline.py     # Script d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ monitor_flow.py       # Flow de monitoring/drift detection
â”‚   â”‚
â”‚   â”œâ”€â”€ feast_repo/               # Repository Feast (Feature Store)
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ repo/                 # Configuration Feast
â”‚   â”‚       â”œâ”€â”€ feature_store.yaml
â”‚   â”‚       â”œâ”€â”€ entities.py       # DÃ©finition des entitÃ©s
â”‚   â”‚       â”œâ”€â”€ data_sources.py   # Sources de donnÃ©es
â”‚   â”‚       â””â”€â”€ feature_views.py  # Vues de features
â”‚   â”‚
â”‚   â”œâ”€â”€ prometheus/                # Configuration Prometheus
â”‚   â”‚   â””â”€â”€ prometheus.yml        # Configuration de scraping
â”‚   â”‚
â”‚   â””â”€â”€ grafana/                   # Configuration Grafana
â”‚       â””â”€â”€ provisioning/         # Provisioning automatique
â”‚           â”œâ”€â”€ datasources/
â”‚           â”‚   â””â”€â”€ prometheus.yml
â”‚           â””â”€â”€ dashboards/
â”‚               â””â”€â”€ json/
â”‚
â”œâ”€â”€ db/                           # Scripts de base de donnÃ©es
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 001_schema.sql        # SchÃ©ma initial PostgreSQL
â”‚
â”œâ”€â”€ data/                         # DonnÃ©es du projet
â”‚   â”œâ”€â”€ seeds/                    # DonnÃ©es d'exemple
â”‚   â”‚   â””â”€â”€ month_000/
â”‚   â”‚       â”œâ”€â”€ users.csv
â”‚   â”‚       â”œâ”€â”€ features.csv
â”‚   â”‚       â””â”€â”€ labels.csv
â”‚   â””â”€â”€ processed/               # DonnÃ©es traitÃ©es
â”‚
â”œâ”€â”€ mlartifacts/                 # Artifacts MLflow
â”‚   â”œâ”€â”€ artifacts/               # ModÃ¨les et artifacts
â”‚   â””â”€â”€ mlflow.db               # Base de donnÃ©es MLflow
â”‚
â”œâ”€â”€ reports/                     # Rapports et documentation
â”‚   â”œâ”€â”€ rapport_tp1.md
â”‚   â”œâ”€â”€ images TP1/
â”‚   â””â”€â”€ evidently/               # Rapports Evidently
â”‚
â”œâ”€â”€ docker-compose.yml           # Configuration Docker Compose
â”œâ”€â”€ .env                        # Variables d'environnement (non versionnÃ©)
â”œâ”€â”€ .gitignore                  # Fichiers Ã  ignorer par Git
â””â”€â”€ README.md                   # Documentation du projet
```

---

## Guide de crÃ©ation d'un nouveau projet

### Ã‰tape 1 : Initialisation du projet

```bash
# CrÃ©er le rÃ©pertoire du projet
mkdir mon-projet-mlops
cd mon-projet-mlops

# Initialiser Git
git init
git remote add origin <votre-repo-git>

# CrÃ©er la structure de base
mkdir -p api services/prefect services/feast_repo/repo services/prometheus services/grafana/provisioning/datasources services/grafana/provisioning/dashboards/json
mkdir -p db/init data/seeds data/processed mlartifacts reports
```

### Ã‰tape 2 : Configuration Docker Compose

CrÃ©er `docker-compose.yml` :

```yaml
services:
  postgres:
    image: postgres:16
    env_file: .env
    volumes:
      - ./db/init:/docker-entrypoint-initdb.d
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  prefect:
    build: ./services/prefect
    depends_on:
      - postgres
      - mlflow
    env_file: .env
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      MLFLOW_TRACKING_URI: http://mlflow:5000
    volumes:
      - ./services/prefect:/opt/prefect/flows
      - ./data:/data
      - ./services/feast_repo/repo:/repo
      - ./reports:/reports

  feast:
    build: ./services/feast_repo
    depends_on:
      - postgres
    environment:
      FEAST_USAGE: "False"
    volumes:
      - ./services/feast_repo/repo:/repo

  api:
    build: ./api
    env_file: .env
    depends_on:
      - postgres
      - feast
      - mlflow
    ports:
      - "8000:8000"
    volumes:
      - ./api:/app
      - ./services/feast_repo/repo:/repo

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0
    command: mlflow server --backend-store-uri sqlite:///mlartifacts/mlflow.db --default-artifact-root mlflow-artifacts:/ --host 0.0.0.0 --port 5000 --serve-artifacts --artifacts-destination /mlartifacts/artifacts
    volumes:
      - "./mlartifacts:/mlartifacts"
    ports:
      - "5000:5000"

  prometheus:
    image: prom/prometheus:v2.55.1
    volumes:
      - ./services/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    depends_on:
      - api

  grafana:
    image: grafana/grafana:11.2.0
    volumes:
      - ./services/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    depends_on:
      - prometheus

volumes:
  pgdata:
  mlartifacts:
  grafana-data:
```

### Ã‰tape 3 : Variables d'environnement

CrÃ©er `.env` :

```env
POSTGRES_USER=your_user
POSTGRES_PASSWORD=your_password
POSTGRES_DB=your_database
```

CrÃ©er `.gitignore` :

```
.env
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
mlartifacts/
*.db
*.sqlite
.DS_Store
```

### Ã‰tape 4 : Configuration de la base de donnÃ©es

CrÃ©er `db/init/001_schema.sql` avec votre schÃ©ma de base de donnÃ©es :

```sql
-- Exemple de schÃ©ma
CREATE TABLE IF NOT EXISTS users (
    user_id TEXT PRIMARY KEY,
    -- autres colonnes
);

CREATE TABLE IF NOT EXISTS features (
    user_id TEXT,
    feature_date DATE,
    -- autres colonnes
    PRIMARY KEY (user_id, feature_date)
);

CREATE TABLE IF NOT EXISTS labels (
    user_id TEXT PRIMARY KEY,
    label_value BOOLEAN
);
```

### Ã‰tape 5 : Configuration de l'API FastAPI

CrÃ©er `api/app.py` :

```python
from fastapi import FastAPI
from pydantic import BaseModel
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response
import time
import mlflow
from feast import FeatureStore

app = FastAPI()

# MÃ©triques Prometheus
REQUEST_COUNT = Counter("api_requests_total", "Total number of API requests")
REQUEST_LATENCY = Histogram("api_request_latency_seconds", "Latency of API requests in seconds")

# Charger le modÃ¨le depuis MLflow
mlflow.set_tracking_uri("http://mlflow:5000")
model = mlflow.sklearn.load_model("models:/your_model_name/Production")

# Feature Store
store = FeatureStore(repo_path="/repo")

class PredictionRequest(BaseModel):
    user_id: str

@app.get("/health")
def health():
    return {"status": "ok"}

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.post("/predict")
def predict(request: PredictionRequest):
    start_time = time.time()
    REQUEST_COUNT.inc()
    
    # RÃ©cupÃ©rer les features depuis Feast
    features = store.get_online_features(
        features=["your_feature_view:feature1", "your_feature_view:feature2"],
        entity_rows=[{"user_id": request.user_id}]
    )
    
    # Faire la prÃ©diction
    prediction = model.predict(features.to_df())
    
    REQUEST_LATENCY.observe(time.time() - start_time)
    
    return {"user_id": request.user_id, "prediction": float(prediction[0])}
```

CrÃ©er `api/requirements.txt` :

```
fastapi
uvicorn[standard]
pydantic
scikit-learn
mlflow
feast
pandas
prometheus-client
psycopg2-binary
```

CrÃ©er `api/Dockerfile` :

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && \
    apt-get install -y --no-install-recommends build-essential libpq-dev && \
    rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Ã‰tape 6 : Configuration Feast (Feature Store)

CrÃ©er `services/feast_repo/repo/feature_store.yaml` :

```yaml
project: your_project
registry: registry.db
provider: local
online_store:
  type: postgres
  connection_string: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
offline_store:
  type: postgres
  connection_string: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
```

CrÃ©er `services/feast_repo/repo/entities.py` :

```python
from feast import Entity

user = Entity(
    name="user_id",
    value_type=ValueType.STRING,
    description="User identifier",
)
```

CrÃ©er `services/feast_repo/repo/data_sources.py` :

```python
from feast.infra.offline_stores.contrib.postgres_offline_store.postgres_source import PostgreSQLSource

your_source = PostgreSQLSource(
    name="your_source",
    query="""
        SELECT user_id, feature_date,
               feature1, feature2, feature3
        FROM your_features_table
    """,
    timestamp_field="feature_date",
)
```

CrÃ©er `services/feast_repo/repo/feature_views.py` :

```python
from feast import FeatureView, Field
from feast.types import Float32, String
from .entities import user
from .data_sources import your_source

your_feature_view = FeatureView(
    name="your_feature_view",
    entities=[user],
    source=your_source,
    ttl=timedelta(days=1),
    schema=[
        Field(name="feature1", dtype=Float32),
        Field(name="feature2", dtype=Float32),
    ],
)
```

CrÃ©er `services/feast_repo/Dockerfile` :

```dockerfile
FROM python:3.11-slim

WORKDIR /repo

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

CMD ["bash", "-c", "tail -f /dev/null"]
```

CrÃ©er `services/feast_repo/requirements.txt` :

```
feast
pandas
psycopg2-binary
SQLAlchemy
```

### Ã‰tape 7 : Configuration Prefect

CrÃ©er `services/prefect/Dockerfile` :

```dockerfile
FROM prefecthq/prefect:3.0.3-python3.11

WORKDIR /opt/prefect/flows

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["bash", "-c", "prefect server start --host 0.0.0.0 --port 4200 & sleep 10 && prefect worker start --pool 'default-agent-pool' --work-queue 'default'"]
```

CrÃ©er `services/prefect/requirements.txt` :

```
prefect
feast
mlflow
scikit-learn
pandas
SQLAlchemy
psycopg2-binary
evidently
great_expectations
```

CrÃ©er `services/prefect/ingest_flow.py` (exemple) :

```python
import os
import pandas as pd
from sqlalchemy import create_engine
from prefect import flow, task

@task
def load_data(file_path: str) -> pd.DataFrame:
    return pd.read_csv(file_path)

@task
def validate_data(df: pd.DataFrame):
    # Validation avec Great Expectations ou pandas
    assert not df.empty, "DataFrame is empty"
    return True

@task
def save_to_db(df: pd.DataFrame, table_name: str):
    engine = create_engine(
        f"postgresql+psycopg2://{os.getenv('POSTGRES_USER')}:"
        f"{os.getenv('POSTGRES_PASSWORD')}@"
        f"{os.getenv('POSTGRES_HOST')}:5432/"
        f"{os.getenv('POSTGRES_DB')}"
    )
    df.to_sql(table_name, engine, if_exists='append', index=False)

@flow(name="ingest_data")
def ingest_flow(file_path: str, table_name: str):
    df = load_data(file_path)
    validate_data(df)
    save_to_db(df, table_name)
    return f"Data ingested into {table_name}"

if __name__ == "__main__":
    ingest_flow("data/seeds/your_data.csv", "your_table")
```

### Ã‰tape 8 : Configuration Prometheus

CrÃ©er `services/prometheus/prometheus.yml` :

```yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: "api"
    metrics_path: /metrics
    static_configs:
      - targets: ["api:8000"]
```

### Ã‰tape 9 : Configuration Grafana

CrÃ©er `services/grafana/provisioning/datasources/prometheus.yml` :

```yaml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
```

### Ã‰tape 10 : DÃ©marrage du projet

```bash
# Construire et dÃ©marrer tous les services
docker compose up -d

# VÃ©rifier le statut
docker compose ps

# Voir les logs
docker compose logs -f api
```

### Ã‰tape 11 : AccÃ¨s aux interfaces

- **API** : http://localhost:8000
- **MLflow UI** : http://localhost:5000
- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3001 (admin/admin par dÃ©faut)
- **Prefect UI** : http://localhost:4200 (si configurÃ©)

---

## Configuration dÃ©taillÃ©e de chaque composant

### PostgreSQL

**RÃ´le** : Base de donnÃ©es principale pour stocker toutes les donnÃ©es

**Configuration** :
- Image : `postgres:16`
- Port : `5432`
- Volumes : 
  - Scripts d'initialisation dans `db/init/`
  - DonnÃ©es persistantes dans volume `pgdata`

**Utilisation** :
- Stocker les donnÃ©es brutes
- Stocker les snapshots temporels pour la reproductibilitÃ©
- Stocker les mÃ©tadonnÃ©es Feast
- Backend pour MLflow (optionnel, ici on utilise SQLite)

### Prefect

**RÃ´le** : Orchestrateur de workflows

**Configuration** :
- Image de base : `prefecthq/prefect:3.0.3-python3.11`
- Port : `4200` (UI)
- Volumes : 
  - Scripts de flows dans `services/prefect/`
  - DonnÃ©es dans `data/`
  - Repository Feast dans `services/feast_repo/repo/`
  - Rapports dans `reports/`

**Flows typiques** :
1. **Ingestion** : Charger et valider les donnÃ©es
2. **Training** : EntraÃ®ner les modÃ¨les
3. **Monitoring** : DÃ©tecter le drift et gÃ©nÃ©rer des rapports

### Feast

**RÃ´le** : Feature Store centralisÃ©

**Configuration** :
- Repository dans `services/feast_repo/repo/`
- Configuration dans `feature_store.yaml`
- Feature views dans `feature_views.py`
- Sources de donnÃ©es dans `data_sources.py`

**Modes d'utilisation** :
- **Offline** : Pour l'entraÃ®nement (historical features)
- **Online** : Pour les prÃ©dictions en temps rÃ©el

### MLflow

**RÃ´le** : Gestion du cycle de vie des modÃ¨les

**Configuration** :
- Image : `ghcr.io/mlflow/mlflow:v2.16.0`
- Port : `5000`
- Backend store : SQLite (ou PostgreSQL)
- Artifact store : `mlartifacts/`

**FonctionnalitÃ©s** :
- Tracking des expÃ©riences
- Registry de modÃ¨les
- DÃ©ploiement de modÃ¨les

### FastAPI

**RÃ´le** : API de prÃ©diction en production

**Configuration** :
- Port : `8000`
- Hot reload : volume montÃ© pour dÃ©veloppement
- MÃ©triques Prometheus : endpoint `/metrics`

**Endpoints typiques** :
- `GET /health` : Health check
- `GET /metrics` : MÃ©triques Prometheus
- `POST /predict` : PrÃ©diction

### Prometheus

**RÃ´le** : Collecte de mÃ©triques

**Configuration** :
- Image : `prom/prometheus:v2.55.1`
- Port : `9090`
- Configuration : `services/prometheus/prometheus.yml`

**MÃ©triques collectÃ©es** :
- Nombre de requÃªtes (Counter)
- Latence des requÃªtes (Histogram)
- Erreurs (Counter)

### Grafana

**RÃ´le** : Visualisation des mÃ©triques

**Configuration** :
- Image : `grafana/grafana:11.2.0`
- Port : `3001` (mappÃ© depuis 3000)
- Provisioning automatique dans `services/grafana/provisioning/`

**Dashboards** :
- RPS (RequÃªtes par seconde)
- Latence moyenne
- Taux d'erreur

### Evidently

**RÃ´le** : DÃ©tection de drift de donnÃ©es

**Configuration** :
- UtilisÃ© dans les flows Prefect
- GÃ©nÃ¨re des rapports HTML/JSON dans `reports/evidently/`

**MÃ©triques** :
- Data drift (covariate drift)
- Target drift (concept drift)
- Data quality

---

## Bonnes pratiques

### 1. Gestion des versions

- Utiliser des tags Git pour marquer les versions importantes
- Documenter les changements dans les commits

### 2. Variables d'environnement

- Ne jamais commiter `.env`
- Utiliser des valeurs par dÃ©faut dans le code
- Documenter les variables nÃ©cessaires

### 3. SÃ©curitÃ©

- Utiliser des mots de passe forts pour PostgreSQL
- Ne pas exposer les services sensibles publiquement
- Utiliser des secrets management en production

### 4. Monitoring

- Configurer des alertes dans Grafana
- Surveiller les mÃ©triques de drift rÃ©guliÃ¨rement
- Documenter les seuils d'alerte

### 5. Tests

- Tester les flows Prefect localement
- Tester l'API avec des donnÃ©es de test
- Valider les features Feast avant le dÃ©ploiement

### 6. Documentation

- Documenter chaque flow Prefect
- Documenter les features Feast
- Maintenir un README Ã  jour

---

## Commandes utiles

### Docker Compose

```bash
# DÃ©marrer tous les services
docker compose up -d

# ArrÃªter tous les services
docker compose down

# Voir les logs
docker compose logs -f [service_name]

# Reconstruire un service
docker compose build [service_name]

# RedÃ©marrer un service
docker compose restart [service_name]
```

### Prefect

```bash
# ExÃ©cuter un flow
docker compose exec prefect python /opt/prefect/flows/your_flow.py

# Voir les flows
docker compose exec prefect prefect flow ls
```

### Feast

```bash
# Appliquer les changements Feast
docker compose exec feast feast apply

# MatÃ©rialiser les features (online store)
docker compose exec feast feast materialize-incremental $(date -u +"%Y-%m-%dT%H:%M:%S")
```

### MLflow

```bash
# Lister les modÃ¨les
docker compose exec mlflow mlflow models list

# Charger un modÃ¨le
docker compose exec mlflow mlflow models serve -m "models:/your_model/Production"
```

---

## DÃ©pannage

### ProblÃ¨mes courants

1. **Port dÃ©jÃ  utilisÃ©** : Modifier les ports dans `docker-compose.yml`
2. **Connexion Ã  PostgreSQL Ã©choue** : VÃ©rifier les variables d'environnement dans `.env`
3. **Feast ne trouve pas les features** : VÃ©rifier que `feast apply` a Ã©tÃ© exÃ©cutÃ©
4. **MLflow ne charge pas le modÃ¨le** : VÃ©rifier que le modÃ¨le est enregistrÃ© et promu en Production
5. **Prometheus ne scrape pas l'API** : VÃ©rifier que l'endpoint `/metrics` fonctionne

### Logs

```bash
# Logs de tous les services
docker compose logs

# Logs d'un service spÃ©cifique
docker compose logs api
docker compose logs prefect
docker compose logs postgres
```

---

## Ressources supplÃ©mentaires

- [Prefect Documentation](https://docs.prefect.io/)
- [Feast Documentation](https://docs.feast.dev/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Evidently Documentation](https://docs.evidentlyai.com/)

---

## Conclusion

Cette architecture MLOps complÃ¨te fournit :

âœ… **Orchestration** avec Prefect  
âœ… **Feature Store** avec Feast  
âœ… **Model Registry** avec MLflow  
âœ… **API de prÃ©diction** avec FastAPI  
âœ… **Monitoring** avec Prometheus et Grafana  
âœ… **Drift Detection** avec Evidently  
âœ… **Validation** avec Great Expectations  
âœ… **Containerisation** avec Docker  

Cette structure est modulaire et peut Ãªtre adaptÃ©e Ã  diffÃ©rents projets ML en modifiant les configurations spÃ©cifiques Ã  votre cas d'usage.

